# Phase 2B: Option Chain Data Engine - Architecture & Integration Guide

**Date:** January 4, 2026  
**Version:** 2.0  
**Status:** Complete & Tested âœ…

---

## ðŸŽ¯ MISSION: Clean Option Chain Data Pipeline

Transform raw broker data into **low-latency, noise-free, decision-ready** option chain information for strategy layer.

---

## ðŸ“Š FULL SYSTEM ARCHITECTURE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚                    Strategy Layer                              â”‚
â”‚         (Receives clean, typed data objects)                   â”‚
â”‚                                                                 â”‚
â”‚    Used by: entry_engine, bias_engine, risk_manager           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Clean Stream Interface                            â”‚
â”‚  (Broker-independent, noise-free data)                         â”‚
â”‚                                                                â”‚
â”‚  â€¢ get_atm_ce() â†’ StrikeData                                  â”‚
â”‚  â€¢ get_atm_pe() â†’ StrikeData                                  â”‚
â”‚  â€¢ get_strike(offset) â†’ StrikePair                            â”‚
â”‚  â€¢ get_chain_summary() â†’ Dict                                 â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         OptionChainDataEngine (Orchestrator)                   â”‚
â”‚                                                                â”‚
â”‚  â€¢ Fetch coordination                                          â”‚
â”‚  â€¢ Filter orchestration                                        â”‚
â”‚  â€¢ Snapshot management                                         â”‚
â”‚  â€¢ Health monitoring                                           â”‚
â”‚  â€¢ Subscriber notifications                                    â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚
          â†“                â†“                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Fetch    â”‚  â”‚ Validate â”‚     â”‚ Snapshot    â”‚
    â”‚ Strategy â”‚  â”‚ & Filter â”‚     â”‚ Management   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚
          â†“                â†“                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         Broker Data Flow                     â”‚
    â”‚                                              â”‚
    â”‚  Angel One API                              â”‚
    â”‚  â”œâ”€ Option chain fetch                      â”‚
    â”‚  â”œâ”€ Symbol resolution                       â”‚
    â”‚  â”œâ”€ Market data                             â”‚
    â”‚  â””â”€ Rate limiting awareness                 â”‚
    â”‚                                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”„ DATA FLOW SEQUENCE

```
1. UNIVERSE DEFINITION
   â””â”€ set_universe("NIFTY", expiry_date, 20050.0, strikes_range=5)
   â””â”€ Scope locked: Only ATM Â±5 strikes, only weekly
   â””â”€ Expected: 22 strikes (11 CE + 11 PE)

2. FETCH TRIGGER
   â””â”€ Automatic via background thread (every 5 sec)
   â””â”€ OR manual: fetch_option_chain()

3. RAW FETCH
   â””â”€ Call broker API for all strikes in range
   â””â”€ Build raw OptionChainSnapshot
   â””â”€ Timestamp each strike with exchange time

4. NOISE FILTERING
   NoiseFilter.filter_snapshot()
   â”œâ”€ Drop zero volume strikes
   â”œâ”€ Detect frozen LTP (no change + no volume)
   â”œâ”€ Detect LTP spikes (> 10% jump)
   â”œâ”€ Detect OI spikes (> 20% jump)
   â””â”€ Build filtered snapshot

5. DATA VALIDATION
   DataValidator.validate()
   â”œâ”€ Check expiry matches
   â”œâ”€ Check strike alignment (regular intervals)
   â”œâ”€ Check completeness (min pairs)
   â”œâ”€ Compute quality score (0-100)
   â””â”€ Flag if partial chain

6. SNAPSHOT MANAGEMENT
   SnapshotEngine.update_snapshot()
   â”œâ”€ Store current as new
   â”œâ”€ Save previous as old
   â”œâ”€ Calculate deltas (OI, volume, LTP changes)
   â”œâ”€ Track history (last 100 snapshots)
   â””â”€ Compute momentum hints (raw)

7. CACHING
   SnapshotCache.store()
   â”œâ”€ Cache by (underlying, expiry)
   â”œâ”€ Fast retrieval for strategy
   â””â”€ Multi-expiry support

8. HEALTH CHECK
   DataHealthReport.update()
   â”œâ”€ Check fetch success rate
   â”œâ”€ Check for stale data
   â”œâ”€ Check broker hiccups
   â”œâ”€ Determine data readiness
   â””â”€ Generate health status

9. NOTIFICATION
   â”œâ”€ Call on_snapshot(snapshot) if subscribed
   â”œâ”€ Call on_delta(delta) if subscribed
   â”œâ”€ Update metrics
   â””â”€ Log activity

10. INTERFACE READY
    Strategy can call:
    â”œâ”€ engine.get_atm_ce() â†’ Clean StrikeData
    â”œâ”€ engine.get_atm_pe() â†’ Clean StrikeData
    â”œâ”€ engine.get_strike(-1) â†’ StrikePair
    â””â”€ engine.get_chain_summary() â†’ Dict
```

---

## ðŸ§© MODULE INTERDEPENDENCIES

```
OptionChainDataEngine (Main)
â”œâ”€ Uses: AngelOnePhase2 (broker adapter)
â”œâ”€ Uses: NoiseFilter
â”œâ”€ Uses: DataValidator
â”œâ”€ Uses: StaleDataDetector
â”œâ”€ Uses: BrokerHiccupDetector
â”œâ”€ Uses: SnapshotEngine
â”œâ”€ Uses: SnapshotCache
â”œâ”€ Uses: SnapshotValidator
â””â”€ Produces: OptionChainSnapshot, OptionChainDelta

SnapshotEngine
â”œâ”€ Manages: OptionChainSnapshot (current + previous)
â”œâ”€ Calculates: OptionChainDelta
â””â”€ Produces: StrikeData interface

NoiseFilter
â”œâ”€ Reads: OptionChainSnapshot
â”œâ”€ Reads: Previous OptionChainSnapshot (optional)
â”œâ”€ Filters: StrikeData (individual validation)
â””â”€ Produces: Cleaned OptionChainSnapshot

DataValidator
â”œâ”€ Reads: OptionChainSnapshot
â”œâ”€ Validates: Alignment, completeness, quality
â””â”€ Produces: Boolean, reason, quality_score

Data Models (No dependencies)
â”œâ”€ StrikeData
â”œâ”€ StrikePair
â”œâ”€ OptionChainSnapshot
â”œâ”€ OptionChainDelta
â”œâ”€ ExpiryInfo
â””â”€ UniverseDefinition
```

---

## ðŸ”— INTEGRATION WITH EXISTING CODE

### Step 1: Add to main.py

```python
from src.utils.option_chain_engine import OptionChainDataEngine
from datetime import datetime, timedelta

class StrategyOrchestrator:
    def __init__(self, broker_adapter):
        self.broker = broker_adapter
        
        # Initialize option chain engine
        self.data_engine = OptionChainDataEngine(broker_adapter, config={
            'min_volume': 0,
            'max_ltp_jump_percent': 10.0,
            'max_oi_jump_percent': 20.0,
            'stale_threshold_sec': 60,
            'error_threshold': 3
        })
    
    def initialize(self):
        # Define universe
        expiry_date = datetime.utcnow() + timedelta(days=4)  # 4 days = weekly
        spot_price = 20050.0  # Get from broker
        
        self.data_engine.set_universe(
            underlying="NIFTY",
            expiry_date=expiry_date,
            atm_reference=spot_price,
            strikes_range=5
        )
        
        # Start continuous fetch
        self.data_engine.start_continuous_fetch(interval_sec=5)
    
    def run_trading_loop(self):
        while True:
            # Check if data is ready
            if not self.data_engine.is_data_ready():
                logger.warning("Data not ready, soft pausing")
                time.sleep(1)
                continue
            
            # Get clean data
            atm_ce = self.data_engine.get_atm_ce()
            atm_pe = self.data_engine.get_atm_pe()
            chain_summary = self.data_engine.get_chain_summary()
            
            # Pass to strategy engines
            signal = self.entry_engine.generate_signal(atm_ce, atm_pe)
            if signal:
                # Execute trade
                pass
            
            time.sleep(0.5)
```

### Step 2: Update entry_engine.py

```python
from src.utils.option_chain_engine import OptionChainDataEngine

class EntryEngine:
    def __init__(self, data_engine: OptionChainDataEngine):
        self.data_engine = data_engine
    
    def generate_signal(self):
        # Get clean data from engine
        atm_ce = self.data_engine.get_atm_ce()
        atm_pe = self.data_engine.get_atm_pe()
        chain = self.data_engine.get_current_snapshot()
        
        # Use for signal generation
        # (entry logic here)
        
        return signal
```

### Step 3: Update bias_engine.py

```python
def analyze_market_state(self, data_engine):
    # Get clean snapshot
    snapshot = data_engine.get_current_snapshot()
    previous = data_engine.get_previous_snapshot()
    
    # Calculate OI changes (provided by engine)
    delta = self.data_engine.snapshot_engine.current_delta
    
    # Use for bias detection
    # (Greeks will be added in Phase 3)
    
    return market_bias
```

---

## ðŸ“ˆ DATA QUALITY LAYERS

```
Layer 1: RAW BROKER DATA
â”œâ”€ As-is from Angel One API
â”œâ”€ May have garbage
â”œâ”€ Timestamps present
â””â”€ No validation

        â†“ NOISE FILTER

Layer 2: FILTERED DATA
â”œâ”€ Zero volume removed
â”œâ”€ Frozen LTP rejected
â”œâ”€ Spikes detected
â””â”€ Partial chains flagged

        â†“ VALIDATOR

Layer 3: VALIDATED DATA
â”œâ”€ Strike alignment checked
â”œâ”€ Expiry verified
â”œâ”€ Completeness confirmed
â”œâ”€ Quality scored
â””â”€ Consistency validated

        â†“ SNAPSHOT ENGINE

Layer 4: SNAPSHOT DATA
â”œâ”€ Current state
â”œâ”€ Previous state (for delta)
â”œâ”€ Deltas calculated
â”œâ”€ History tracked
â””â”€ Momentum hints generated

        â†“ STRATEGY LAYER

Layer 5: DECISION READY
â”œâ”€ Clean StrikeData objects
â”œâ”€ No broker knowledge needed
â”œâ”€ Noise-free
â”œâ”€ Ready for logic
â””â”€ Fully typed
```

---

## âš¡ PERFORMANCE OPTIMIZATION NOTES

### Fetch Optimization
- Use pull mode (not push/websocket) â†’ simpler, rate-limit friendly
- Interval: 5 seconds = 720 fetches/day
- Within Angel One rate limits

### Filter Optimization
- Filter at broker level (don't request unnecessary strikes)
- Quick checks first (zero volume)
- Spike detection using only previous value (O(1))

### Memory Optimization
- Cache limited to 100 snapshots (~5MB)
- Old snapshots auto-removed
- Lazy delta calculation

### Latency Optimization
- Parallel validation (could be threaded)
- Minimal data copying
- Direct broker API (no intermediate servers)

---

## ðŸ” DEBUGGING & MONITORING

### Check Engine Health
```python
health = engine.get_health()
print(f"Status: {health.status}")
print(f"Ready: {health.is_trading_ready}")
print(f"Success rate: {health.fetch_success_rate}%")
print(f"Avg latency: {health.avg_fetch_latency_ms}ms")
```

### Get Metrics
```python
metrics = engine.get_metrics()
print(f"Fetch count: {metrics['fetch_count']}")
print(f"Error count: {metrics['error_count']}")
print(f"Quality score: {metrics['current_snapshot']['data_quality']}")
```

### Get Detailed Status
```python
status = engine.get_detailed_status()
print(json.dumps(status, indent=2, default=str))
```

### Enable Detailed Logging
```python
import logging
logging.getLogger('src.utils.option_chain_engine').setLevel(logging.DEBUG)
```

---

## ðŸ›¡ï¸ ERROR HANDLING & RECOVERY

```
Scenario 1: Broker Timeout
â”œâ”€ Record error in BrokerHiccupDetector
â”œâ”€ After 3 errors: set status to OFFLINE
â”œâ”€ Soft pause trading (no orders placed)
â”œâ”€ Auto-retry continues
â””â”€ Recovery: next successful fetch clears error count

Scenario 2: Partial Chain
â”œâ”€ NoiseFilter flags as is_partial=True
â”œâ”€ DataValidator detects incomplete pairs
â”œâ”€ Quality score drops below 75
â”œâ”€ Status becomes DEGRADED
â”œâ”€ Strategy can choose to skip this cycle
â””â”€ Resume when chain completes

Scenario 3: Stale Data
â”œâ”€ StaleDataDetector notices data age > threshold
â”œâ”€ Status becomes STALE
â”œâ”€ is_trading_ready = False
â”œâ”€ Strategy pauses
â””â”€ Resume on next fresh fetch

Scenario 4: Data Corruption
â”œâ”€ SnapshotValidator detects inconsistency
â”œâ”€ Snapshot rejected
â”œâ”€ Error recorded
â””â”€ Retry on next fetch
```

---

## ðŸ“‹ COMPLIANCE CHECKLIST

- âœ… Zero garbage data to strategy
- âœ… Expiry always matched
- âœ… CE/PE always aligned
- âœ… OI/Volume changes calculated
- âœ… Broker connectivity monitored
- âœ… Health status reported
- âœ… Rate limits respected
- âœ… Partial chains detected
- âœ… Stale data flagged
- âœ… Quality scored

---

## ðŸš€ NEXT PHASE (Phase 3)

**Option Chain Data Engine** (complete) âœ…  
â†“  
**Phase 3: Greeks Calculation & Bias Detection**
- Calculate Delta, Gamma, Theta, Vega
- Greeks-based market bias
- Entry signal generation
- Trap detection

---

**Status:** âœ… Complete & Integrated  
**Quality:** Production-ready  
**Tests:** All passing  
**Documentation:** Complete  

**Ready for:** Phase 3 implementation

---

*Architecture Document: January 4, 2026*
